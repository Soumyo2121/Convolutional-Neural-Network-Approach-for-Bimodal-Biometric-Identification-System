{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "41a98e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies \n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5edee433",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow dependencies- functional api\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Conv2D, Dense, MaxPooling2D, Input, Flatten\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f9f9e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Siamese distance layer\n",
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        \n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        return tf.math.abs(input_embedding - validation_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5f8c88a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "#reload model\n",
    "facemodel = tf.keras.models.load_model('facesiamesemodel.h5', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})\n",
    "\n",
    "fpmodel = tf.keras.models.load_model('fpsiamesemodel.h5', custom_objects={'L1Dist':L1Dist, 'BinaryCrossentropy':tf.losses.BinaryCrossentropy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c1e9f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#face preprocessing function\n",
    "def facepreprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    img = img/255.0\n",
    "    return img\n",
    "\n",
    "#fingerprint preprocessing function\n",
    "def fppreprocess(file_path):\n",
    "    byte_img = tf.io.read_file(file_path) \n",
    "    img = tf.io.decode_bmp(byte_img, channels=3)\n",
    "    img = tf.image.resize(img, (100,100))\n",
    "    img = img/255.0\n",
    "    return img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ff2156",
   "metadata": {},
   "source": [
    "## OpenCV Img capture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ff2e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = frame[120:120+250,200:200+250, :]\n",
    "    \n",
    "    cv2.imshow('verification', frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('v'):\n",
    "        cv2.imwrite(os.path.join('face_input_images', 'input_image.jpg'), frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca681f19",
   "metadata": {},
   "source": [
    "## Face Verification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "03453cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def faceverify(facemodel, detection_threshold, verification_threshold):\n",
    "   \n",
    "    #verification Threshold: proportion of positive predictions/ total positive samples\n",
    "    results = []\n",
    "    for image in os.listdir('faceverification_images'):\n",
    "        input_img = facepreprocess('./face_input_images/input_image.jpg')\n",
    "        validation_img = facepreprocess(os.path.join('faceverification_images', image))\n",
    "        \n",
    "        # make predictions\n",
    "        result = facemodel.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "    \n",
    "    #detection Threshold: metric above which a prediction is considered positive   \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    #verification Threshold: proportion of positive predictions/ total positive samples\n",
    "    verification = detection / len(os.listdir('faceverification_images'))\n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5244a90f",
   "metadata": {},
   "source": [
    "## Run Face Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "145212b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 142ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "results, faceverified = faceverify(facemodel, 0.5, 0.5)\n",
    "print(faceverified)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9b46d2",
   "metadata": {},
   "source": [
    "## Fingerprint verification function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bce14ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpverify(fpmodel, detection_threshold, verification_threshold):\n",
    "   \n",
    "    #verification Threshold: proportion of positive predictions/ total positive samples\n",
    "    results = []\n",
    "    for image in os.listdir('fpverification_images'):\n",
    "        input_img = fppreprocess('./fpinput/input_image.jpg')\n",
    "        validation_img = fppreprocess(os.path.join('fpverification_images', image))\n",
    "        \n",
    "        # make predictions\n",
    "        result = fpmodel.predict(list(np.expand_dims([input_img, validation_img], axis=1)))\n",
    "        results.append(result)\n",
    "    \n",
    "    #detection Threshold: metric above which a prediction is considered positive   \n",
    "    detection = np.sum(np.array(results) > detection_threshold)\n",
    "    #verification Threshold: proportion of positive predictions/ total positive samples\n",
    "    verification = detection / len(os.listdir('fpverification_images'))\n",
    "    verified = verification > verification_threshold\n",
    "    \n",
    "    return results, verified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c3f174",
   "metadata": {},
   "source": [
    "## Run fingerprint verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "50368203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 85ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "results, fpverified = fpverify(fpmodel, 0.4, 0.4)\n",
    "print(fpverified)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c959f719",
   "metadata": {},
   "source": [
    "## AND Gate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cb7a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    " def AND (a, b):\n",
    " \n",
    "    if a == True and b == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "06732fb1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The verification status is: True\n"
     ]
    }
   ],
   "source": [
    "final_verified = AND(faceverified, fpverified)\n",
    "print('The verification status is:', final_verified )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c6586a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
